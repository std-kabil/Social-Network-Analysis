\section{Related Works}

This section briefly reviews the main ideas that support the methods used in this project. The goal is not to survey everything, but to explain why the selected approaches are reasonable for a large social network dataset.

\subsection{Social network datasets and graph analysis}
Large online social networks have been widely used as benchmarks for studying connectivity, user interaction patterns, and community structure. The Pokec dataset is distributed through SNAP and has become a common dataset for graph mining research.

In network science, core concepts such as degree distribution, clustering, components, and shortest paths are standard tools for describing the topology of a graph~\cite{newman2010,easley2010}. For very large graphs, the main practical challenge is that several exact computations are too expensive, so researchers rely on approximations and sampling.

\subsection{Small-world phenomenon and ``six degrees''}
The ``six degrees of separation'' idea is commonly associated with Milgram's social experiment~\cite{milgram1967}. In graph terms, the concept is related to the distribution of shortest path lengths between nodes.

Watts and Strogatz popularized the small-world model, showing that networks can have both high clustering and short average path lengths~\cite{watts1998}. Newman also discussed how these properties can be measured and interpreted in large networks~\cite{newman2010}.

In practice, computing all-pairs shortest paths is impossible for graphs with millions of nodes. Therefore, many studies use random sampling of node pairs to estimate path-length distributions. This is the approach adopted in this project.

\subsection{Community detection and modularity}
Community detection aims to split a graph into groups of nodes with dense internal connections and sparse external connections. A widely used approach for large graphs is the Louvain method, which optimizes modularity in a greedy, hierarchical manner~\cite{blondel2008}.

Louvain is attractive because it is relatively fast compared to many alternatives, it often produces meaningful partitions on social networks, and it provides a single scalar (modularity) that helps quantify how strong the community structure is.

However, community detection on the full Pokec graph is heavy. Therefore, this project applies Louvain on a sampled subgraph, with a clear explanation of the tradeoff: the result reflects the sampled region and not necessarily the entire network.

\subsection{Centrality measures and scalability}
Centrality measures quantify which nodes appear important in a network. Degree centrality is simple and scalable, while betweenness centrality is informative but expensive because it relies on shortest paths. NetworkX supports an approximation by sampling $k$ source nodes, which provides a usable ranking for large graphs when $k$ is small.

\subsection{Link prediction: classical similarity features and ML baselines}
Link prediction asks whether a pair of nodes is likely to have a link (or to form a link in the future). A classical approach is to compute similarity scores such as Common Neighbors, Jaccard coefficient, Adamic--Adar, and Preferential Attachment~\cite{liben2007,adamic2003}. A common next step is to use these scores as features for a simple classifier such as logistic regression.

In this project, link prediction is not the main focus, but it is used as a small ML extension to make the project richer while staying computationally lightweight.

\subsection{Tools and reproducibility}
NetworkX provides a flexible Python interface for graphs, Streamlit supports interactive dashboards, and Plotly supports interactive graphs and HTML exports. The engineering work emphasizes reproducibility and clarity: results shown in the Streamlit UI are generated from the current run and can be exported to files for later use.
