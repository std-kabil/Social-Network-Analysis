"""
Streamlit Dashboard for Social Network Analysis
Six Degrees of Separation - soc-Pokec Dataset
"""

import streamlit as st
import networkx as nx
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from pathlib import Path
import json
import random
from collections import Counter

# Page configuration
st.set_page_config(
    page_title="Six Degrees of Separation",
    page_icon="üåê",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1E88E5;
        text-align: center;
        margin-bottom: 1rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        border-radius: 10px;
        padding: 1rem;
        text-align: center;
    }
    .stMetric {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
    }
</style>
""", unsafe_allow_html=True)

# Constants
DATA_DIR = Path('data')
OUTPUTS_DIR = Path('outputs')


@st.cache_resource
def load_graph():
    """Load the network graph (cached for performance)."""
    edges_file = DATA_DIR / 'soc-pokec-relationships.txt'
    
    if not edges_file.exists():
        return None, None
    
    with st.spinner("Loading graph... This may take a few minutes."):
        G = nx.read_edgelist(str(edges_file), create_using=nx.DiGraph(), nodetype=int)
        G_undirected = G.to_undirected()
    
    return G, G_undirected


@st.cache_data
def load_results():
    """Load pre-computed analysis results."""
    results_file = OUTPUTS_DIR / 'analysis_results.json'
    
    if results_file.exists():
        with open(results_file, 'r') as f:
            return json.load(f)
    return None


@st.cache_data
def get_largest_component_nodes(_G_undirected):
    """Get nodes in the largest connected component."""
    if _G_undirected is None:
        return []
    components = list(nx.connected_components(_G_undirected))
    largest_cc = max(components, key=len)
    return list(largest_cc)


def compute_path(G_undirected, source, target):
    """Compute shortest path between two nodes."""
    try:
        path = nx.shortest_path(G_undirected, source, target)
        return path
    except nx.NetworkXNoPath:
        return None
    except nx.NodeNotFound:
        return None


def create_path_visualization(G_undirected, path):
    """Create a visualization of the path between nodes."""
    if path is None or len(path) < 2:
        return None
    
    # Create subgraph with path nodes and their neighbors
    path_set = set(path)
    neighbor_nodes = set()
    for node in path:
        neighbors = list(G_undirected.neighbors(node))[:5]  # Limit neighbors
        neighbor_nodes.update(neighbors)
    
    all_nodes = path_set | neighbor_nodes
    subgraph = G_undirected.subgraph(all_nodes).copy()
    
    # Compute layout
    pos = nx.spring_layout(subgraph, k=2, iterations=50, seed=42)
    
    # Create edge traces
    edge_x, edge_y = [], []
    path_edge_x, path_edge_y = [], []
    
    for edge in subgraph.edges():
        x0, y0 = pos[edge[0]]
        x1, y1 = pos[edge[1]]
        
        # Check if edge is on the path
        is_path_edge = (edge[0] in path_set and edge[1] in path_set and
                       abs(path.index(edge[0]) - path.index(edge[1])) == 1)
        
        if is_path_edge:
            path_edge_x.extend([x0, x1, None])
            path_edge_y.extend([y0, y1, None])
        else:
            edge_x.extend([x0, x1, None])
            edge_y.extend([y0, y1, None])
    
    # Regular edges
    edge_trace = go.Scatter(
        x=edge_x, y=edge_y,
        line=dict(width=0.5, color='#ccc'),
        hoverinfo='none',
        mode='lines'
    )
    
    # Path edges (highlighted)
    path_edge_trace = go.Scatter(
        x=path_edge_x, y=path_edge_y,
        line=dict(width=3, color='#E53935'),
        hoverinfo='none',
        mode='lines',
        name='Path'
    )
    
    # Node traces
    node_x = [pos[node][0] for node in subgraph.nodes()]
    node_y = [pos[node][1] for node in subgraph.nodes()]
    node_colors = ['#E53935' if node in path_set else '#90CAF9' for node in subgraph.nodes()]
    node_sizes = [20 if node in path_set else 10 for node in subgraph.nodes()]
    node_text = [f"Node {node}" + (" (on path)" if node in path_set else "") for node in subgraph.nodes()]
    
    node_trace = go.Scatter(
        x=node_x, y=node_y,
        mode='markers+text',
        hoverinfo='text',
        text=[str(n) if n in path_set else '' for n in subgraph.nodes()],
        textposition='top center',
        hovertext=node_text,
        marker=dict(
            color=node_colors,
            size=node_sizes,
            line=dict(width=1, color='white')
        )
    )
    
    fig = go.Figure(
        data=[edge_trace, path_edge_trace, node_trace],
        layout=go.Layout(
            title=f'Path Visualization: {len(path)-1} degrees of separation',
            showlegend=False,
            hovermode='closest',
            margin=dict(b=20, l=5, r=5, t=40),
            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            plot_bgcolor='white',
            height=500
        )
    )
    
    return fig


def main():
    # Header
    st.markdown('<h1 class="main-header">üåê Six Degrees of Separation</h1>', unsafe_allow_html=True)
    st.markdown('<p style="text-align: center; color: #666;">Social Network Analysis on soc-Pokec Dataset</p>', unsafe_allow_html=True)
    
    # Sidebar
    st.sidebar.title("Navigation")
    page = st.sidebar.radio(
        "Select Page",
        ["üìä Dashboard", "üîç Path Finder", "üìà Network Metrics", "üë• Communities", "‚ÑπÔ∏è About"]
    )
    
    # Load data
    G, G_undirected = load_graph()
    results = load_results()
    
    if G is None:
        st.warning("‚ö†Ô∏è Dataset not found. Please run the Jupyter notebook first to download and process the data.")
        st.info("Run `main_analysis.ipynb` to download the soc-Pokec dataset and generate analysis results.")
        
        # Show demo mode
        st.markdown("---")
        st.subheader("Demo Mode")
        st.write("Showing sample statistics based on expected results:")
        
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("Nodes", "1.6M")
        col2.metric("Edges", "30M")
        col3.metric("Avg. Separation", "~4.5")
        col4.metric("Communities", "~200")
        return
    
    # Page routing
    if page == "üìä Dashboard":
        show_dashboard(G, G_undirected, results)
    elif page == "üîç Path Finder":
        show_path_finder(G, G_undirected)
    elif page == "üìà Network Metrics":
        show_network_metrics(G, G_undirected, results)
    elif page == "üë• Communities":
        show_communities(G_undirected, results)
    elif page == "‚ÑπÔ∏è About":
        show_about()


def show_dashboard(G, G_undirected, results):
    """Main dashboard view."""
    st.header("üìä Network Overview")
    
    # Key metrics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Total Nodes", f"{G.number_of_nodes():,}")
    with col2:
        st.metric("Total Edges", f"{G.number_of_edges():,}")
    with col3:
        if results:
            avg_sep = results['degrees_of_separation']['average']
            st.metric("Avg. Separation", f"{avg_sep:.2f}")
        else:
            st.metric("Avg. Separation", "Run analysis")
    with col4:
        if results:
            num_comm = results['community_detection']['num_communities']
            st.metric("Communities", f"{num_comm}")
        else:
            st.metric("Communities", "Run analysis")
    
    st.markdown("---")
    
    # Visualizations
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Path Length Distribution")
        if results:
            # Create distribution from results
            avg = results['degrees_of_separation']['average']
            std = results['degrees_of_separation']['std']
            
            # Simulate distribution
            np.random.seed(42)
            simulated = np.random.normal(avg, std, 10000)
            simulated = np.clip(simulated, 1, 12).astype(int)
            
            fig = px.histogram(
                x=simulated,
                nbins=12,
                labels={'x': 'Degrees of Separation', 'y': 'Frequency'},
                color_discrete_sequence=['#1E88E5']
            )
            fig.add_vline(x=avg, line_dash="dash", line_color="red", 
                         annotation_text=f"Mean: {avg:.2f}")
            fig.add_vline(x=6, line_dash="dot", line_color="green",
                         annotation_text="Six Degrees")
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("Run the analysis notebook to see the distribution.")
    
    with col2:
        st.subheader("Degree Distribution (Log-Log)")
        # Sample degree distribution
        sample_nodes = random.sample(list(G_undirected.nodes()), min(50000, G_undirected.number_of_nodes()))
        degrees = [G_undirected.degree(n) for n in sample_nodes]
        degree_counts = Counter(degrees)
        
        fig = px.scatter(
            x=list(degree_counts.keys()),
            y=list(degree_counts.values()),
            log_x=True,
            log_y=True,
            labels={'x': 'Degree', 'y': 'Frequency'},
            color_discrete_sequence=['#43A047']
        )
        fig.update_traces(marker=dict(size=5, opacity=0.6))
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
    
    # Summary table
    st.subheader("Network Summary")
    if results:
        summary_df = pd.DataFrame({
            'Metric': [
                'Total Nodes', 'Total Edges (Directed)', 'Avg. Degrees of Separation',
                'Average Degree', 'Network Density', 'Clustering Coefficient',
                'Reciprocity', 'Modularity'
            ],
            'Value': [
                f"{results['dataset']['nodes']:,}",
                f"{results['dataset']['edges_directed']:,}",
                f"{results['degrees_of_separation']['average']:.2f}",
                f"{results['network_metrics']['average_degree']:.2f}",
                f"{results['network_metrics']['density']:.6f}",
                f"{results['network_metrics']['average_clustering']:.4f}",
                f"{results['network_metrics']['reciprocity']:.4f}",
                f"{results['community_detection']['modularity']:.4f}"
            ]
        })
        st.dataframe(summary_df, use_container_width=True, hide_index=True)


def show_path_finder(G, G_undirected):
    """Interactive path finder between two nodes."""
    st.header("üîç Path Finder")
    st.write("Find the shortest path (degrees of separation) between any two users.")
    
    # Get sample nodes for suggestions
    lcc_nodes = get_largest_component_nodes(G_undirected)
    
    if not lcc_nodes:
        st.error("Could not load graph data.")
        return
    
    col1, col2 = st.columns(2)
    
    with col1:
        source = st.number_input(
            "Source Node ID",
            min_value=1,
            max_value=max(lcc_nodes),
            value=random.choice(lcc_nodes[:1000]),
            help="Enter a user ID"
        )
    
    with col2:
        target = st.number_input(
            "Target Node ID",
            min_value=1,
            max_value=max(lcc_nodes),
            value=random.choice(lcc_nodes[:1000]),
            help="Enter a user ID"
        )
    
    col1, col2, col3 = st.columns([1, 1, 2])
    
    with col1:
        if st.button("üîç Find Path", type="primary"):
            with st.spinner("Computing shortest path..."):
                path = compute_path(G_undirected, source, target)
                
                if path:
                    st.success(f"‚úÖ Found path with **{len(path)-1} degrees** of separation!")
                    st.write(f"**Path**: {' ‚Üí '.join(map(str, path))}")
                    
                    # Visualize
                    fig = create_path_visualization(G_undirected, path)
                    if fig:
                        st.plotly_chart(fig, use_container_width=True)
                else:
                    st.error("‚ùå No path found between these nodes.")
    
    with col2:
        if st.button("üé≤ Random Pair"):
            st.rerun()
    
    # Statistics
    st.markdown("---")
    st.subheader("Quick Stats")
    
    if source in G_undirected:
        col1, col2 = st.columns(2)
        with col1:
            st.metric(f"Node {source} Degree", G_undirected.degree(source))
        with col2:
            if target in G_undirected:
                st.metric(f"Node {target} Degree", G_undirected.degree(target))


def show_network_metrics(G, G_undirected, results):
    """Display detailed network metrics."""
    st.header("üìà Network Metrics")
    
    if results:
        # Degrees of Separation
        st.subheader("Degrees of Separation Statistics")
        col1, col2, col3, col4, col5 = st.columns(5)
        
        dos = results['degrees_of_separation']
        col1.metric("Average", f"{dos['average']:.2f}")
        col2.metric("Median", f"{dos['median']:.2f}")
        col3.metric("Std Dev", f"{dos['std']:.2f}")
        col4.metric("Min", dos['min'])
        col5.metric("Max", dos['max'])
        
        st.markdown("---")
        
        # Network Properties
        st.subheader("Network Properties")
        col1, col2, col3, col4 = st.columns(4)
        
        nm = results['network_metrics']
        col1.metric("Average Degree", f"{nm['average_degree']:.2f}")
        col2.metric("Density", f"{nm['density']:.6f}")
        col3.metric("Clustering Coeff.", f"{nm['average_clustering']:.4f}")
        col4.metric("Reciprocity", f"{nm['reciprocity']:.4f}")
        
        st.markdown("---")
        
        # Top Nodes
        st.subheader("Top Influential Nodes")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**By PageRank**")
            pr_df = pd.DataFrame(results['top_nodes']['by_pagerank'], columns=['Node ID', 'PageRank'])
            st.dataframe(pr_df, use_container_width=True, hide_index=True)
        
        with col2:
            st.write("**By Degree Centrality**")
            dc_df = pd.DataFrame(results['top_nodes']['by_degree'], columns=['Node ID', 'Centrality'])
            st.dataframe(dc_df, use_container_width=True, hide_index=True)
    else:
        st.info("Run the analysis notebook to compute detailed metrics.")
        
        # Show basic stats from graph
        st.subheader("Basic Statistics (Live)")
        col1, col2, col3 = st.columns(3)
        col1.metric("Nodes", f"{G.number_of_nodes():,}")
        col2.metric("Edges (Directed)", f"{G.number_of_edges():,}")
        col3.metric("Edges (Undirected)", f"{G_undirected.number_of_edges():,}")


def show_communities(G_undirected, results):
    """Display community detection results."""
    st.header("üë• Community Structure")
    
    if results:
        cd = results['community_detection']
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Number of Communities", cd['num_communities'])
        with col2:
            st.metric("Modularity Score", f"{cd['modularity']:.4f}")
        
        st.markdown("---")
        
        st.subheader("What is Modularity?")
        st.write("""
        **Modularity** measures the strength of division of a network into communities.
        - Values range from -0.5 to 1
        - Higher values indicate stronger community structure
        - Values > 0.3 typically indicate significant community structure
        """)
        
        # Modularity gauge
        fig = go.Figure(go.Indicator(
            mode="gauge+number",
            value=cd['modularity'],
            domain={'x': [0, 1], 'y': [0, 1]},
            gauge={
                'axis': {'range': [0, 1]},
                'bar': {'color': "#1E88E5"},
                'steps': [
                    {'range': [0, 0.3], 'color': "#ffcdd2"},
                    {'range': [0.3, 0.5], 'color': "#fff9c4"},
                    {'range': [0.5, 1], 'color': "#c8e6c9"}
                ],
                'threshold': {
                    'line': {'color': "red", 'width': 4},
                    'thickness': 0.75,
                    'value': 0.3
                }
            },
            title={'text': "Modularity Score"}
        ))
        fig.update_layout(height=300)
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("Run the analysis notebook to see community detection results.")


def show_about():
    """About page with project information."""
    st.header("‚ÑπÔ∏è About This Project")
    
    st.markdown("""
    ## Six Degrees of Separation
    
    This project empirically tests the famous "six degrees of separation" theory using 
    the **soc-Pokec** social network dataset from Stanford SNAP.
    
    ### The Theory
    The six degrees of separation is the idea that all people are six or fewer social 
    connections away from each other. This concept suggests that a chain of "friend of 
    a friend" statements can connect any two people in a maximum of six steps.
    
    ### Dataset
    - **Source**: [Stanford SNAP](https://snap.stanford.edu/data/soc-Pokec.html)
    - **Network**: Pokec (Slovak social network, similar to Facebook)
    - **Nodes**: ~1.6 million users
    - **Edges**: ~30 million friendships
    
    ### Techniques Used
    - **Graph Analysis**: NetworkX
    - **Community Detection**: Louvain Algorithm
    - **Centrality Measures**: PageRank, Betweenness, Degree
    - **Link Prediction**: Jaccard, Adamic-Adar
    
    ### Key Findings
    Our analysis confirms the small-world property of social networks, with an average 
    degrees of separation of approximately **4-5**, well below the theoretical 6.
    
    ---
    
    *Developed as part of a Data Mining course project.*
    """)
    
    st.markdown("---")
    
    st.subheader("Project Structure")
    st.code("""
Social-Network-Analysis/
‚îú‚îÄ‚îÄ main_analysis.ipynb    # Main analysis notebook
‚îú‚îÄ‚îÄ app.py                 # This Streamlit dashboard
‚îú‚îÄ‚îÄ requirements.txt       # Dependencies
‚îú‚îÄ‚îÄ data/                  # Dataset files
‚îî‚îÄ‚îÄ outputs/               # Generated results
    """)


if __name__ == "__main__":
    main()
